{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGSMITH_API_KEY\"]=os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001CBDF9DB450> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001CBDF9F4ED0> root_client=<openai.OpenAI object at 0x000001CBDC9CF050> root_async_client=<openai.AsyncOpenAI object at 0x000001CBDF9DB610> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input and get response form LLM\n",
    "\n",
    "result=llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a category of artificial intelligence systems designed to generate data or content that is similar to what humans might produce. This technology leverages machine learning models, particularly deep learning, to create various types of media, including text, images, audio, and even video. Some of the most notable types of generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs)**: This architecture involves two neural networks competing against each otherâ€”a generator and a discriminator. The generator creates new data, while the discriminator evaluates its authenticity. The competition enhances the quality of the generated data.\\n\\n2. **Variational Autoencoders (VAEs)**: These models are used for generating complex data types. VAEs compress data into a latent space, then decode it back, which can be useful for generating data similar to the input.\\n\\n3. **Transformers**: Models such as GPT (Generative Pre-trained Transformer) are influential in text generation. They generate coherent, human-like text by predicting the next token in a sequence given the preceding ones.\\n\\nGenerative AI has various applications across different fields. In creative industries, it helps in generating art, music, and design prototypes. In entertainment, it can create virtual characters or simulate environments. In language processing, it's used for chatbots, translation, and content creation. Additionally, in research and innovation, generative AI aids in drug discovery and simulating complex physics scenarios.\\n\\nDespite its powerful capabilities, generative AI poses challenges such as ethical concerns regarding deepfakes, copyright issues, and the potential for misuse in creating misleading or harmful content. Consequently, the development and deployment of generative AI require careful consideration of ethical guidelines and regulations.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 343, 'prompt_tokens': 13, 'total_tokens': 356, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_de57b65c90', 'id': 'chatcmpl-BKHB9b7jHFyiuFGJqyYXU6FgLIBSM', 'finish_reason': 'stop', 'logprobs': None} id='run-329870d1-25a7-4290-86ff-4944b1871215-0' usage_metadata={'input_tokens': 13, 'output_tokens': 343, 'total_tokens': 356, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt Template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answers based on the questions\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    "\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Langsmith is a platform designed to enhance the development experience for developers working with language models, particularly those building applications using LangChain. It focuses on providing robust tools for monitoring, testing, debugging, and evaluating language applications. Langsmith offers features such as detailed tracing and logging, which allow developers to visualize and understand the interactions between different components in their application. Additionally, it provides capabilities to fine-tune and improve the performance of language applications by identifying bottlenecks and issues, thereby enabling developers to create more reliable and efficient AI-driven solutions.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 33, 'total_tokens': 142, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_898ac29719', 'id': 'chatcmpl-BKHQRHAi9PAN9vW3PAHgyDtdd1CJn', 'finish_reason': 'stop', 'logprobs': None} id='run-797b4966-cf5e-4262-8f2e-2af2f59596b3-0' usage_metadata={'input_tokens': 33, 'output_tokens': 109, 'total_tokens': 142, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## chain \n",
    "chain=prompt|llm\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Langsmith is a tool designed to assist in building and debugging applications powered by large language models (LLMs). It focuses on improving the workflow of developers working with LLM applications by offering capabilities such as tracing and visualization, evaluation, and monitoring.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Traces**: Langsmith provides detailed traces of LLM applications, helping developers understand the flow of information and pinpoint areas for optimization.\n",
      "   \n",
      "2. **Evaluation**: It offers robust tools to evaluate the performance of language models in various scenarios, allowing for a fine-tuned approach to improvement.\n",
      "\n",
      "3. **Monitoring**: The platform includes features for monitoring model performance over time to ensure reliability and effectiveness in production environments.\n",
      "\n",
      "4. **Integration**: Langsmith integrates with popular LLM frameworks to streamline the debugging and optimization process.\n",
      "\n",
      "Overall, Langsmith is aimed at providing a comprehensive suite of tools to enhance the development and maintenance of applications reliant on advanced language models, ensuring they are both efficient and effective.\n"
     ]
    }
   ],
   "source": [
    "## stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser=StrOutputParser()\n",
    "chain=prompt|llm|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
